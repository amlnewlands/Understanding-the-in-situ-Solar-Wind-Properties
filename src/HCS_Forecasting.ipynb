{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the in-situ Solar Wind Properties with Machine Learning and Artificial Intelligence\n",
    "\n",
    "\n",
    "Project Abstract: \n",
    "With the rapid increase of the in-situ measurements of the solar wind plasma, traditional data analysis methods are no longer sufficient for Heliophysics scientists to fully comprehend the scientific insights embedded within the data. Applications of Machine learning (ML) and Artificial Intelligence (AI) techniques on the solar data in order to perform feature selection, dimension reduction and clustering is the major goal of this proposal.\n",
    "\n",
    "Project Outcome:\n",
    "1). The importance ranking of the solar wind input data.\n",
    "2). Visualization of the solar wind data in 2D, after the dimension reduction.\n",
    "3). Labels of the clustering.\n",
    "4). Prediction of the monthly sunspot number and the indexes of the HCS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analytics / Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "# from pydantic_settings import BaseSettings #not sure if it's needed\n",
    "# from ydata_profiling import ProfileReport\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, DecomposeResult\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#pip install ydata-profiling\n",
    "#pip install pydantic-settings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe delete\n",
    "# import sys\n",
    "# sys.path.append('/path/to/your/module')\n",
    "#from fractional_date_converter import fractional_date_to_actual_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSVs\n",
    "\n",
    "#Just HCS\n",
    "hcs_df = pd.read_csv('../data/HCS Cleaned.csv')\n",
    "hcs_df['actual_date'] = pd.to_datetime(hcs_df['actual_date'])  \n",
    "\n",
    "#HCS + Sunspots\n",
    "hcs_sun = pd.read_csv(\"../data/HCS + Sunspots.csv\")\n",
    "hcs_sun['date'] = pd.to_datetime(hcs_sun['date']) \n",
    "\n",
    "#HCS + Sinsports + ACE\n",
    "hcs_sun_ace= pd.read_csv(\"../data/HCS + Sunspots + ACE.csv\")\n",
    "hcs_sun_ace['date'] = pd.to_datetime(hcs_sun_ace['date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>SD_70</th>\n",
       "      <th>SL_70</th>\n",
       "      <th>SL_70_log10</th>\n",
       "      <th>fyear_CS</th>\n",
       "      <th>monthly_sunspots</th>\n",
       "      <th>std</th>\n",
       "      <th>observations</th>\n",
       "      <th>date</th>\n",
       "      <th>smoothed_sunspots</th>\n",
       "      <th>SD_70*10</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temp</th>\n",
       "      <th>He4toprotons</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>2</td>\n",
       "      <td>12.301438</td>\n",
       "      <td>82.789337</td>\n",
       "      <td>1.917974</td>\n",
       "      <td>1998.123</td>\n",
       "      <td>50.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>559</td>\n",
       "      <td>1998-02-01</td>\n",
       "      <td>61.745833</td>\n",
       "      <td>123.014380</td>\n",
       "      <td>10.668186</td>\n",
       "      <td>55818.621443</td>\n",
       "      <td>0.022320</td>\n",
       "      <td>377.004722</td>\n",
       "      <td>-1.249865</td>\n",
       "      <td>-0.740865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>3</td>\n",
       "      <td>12.602894</td>\n",
       "      <td>159.079344</td>\n",
       "      <td>2.008504</td>\n",
       "      <td>1998.204</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>571</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>65.370833</td>\n",
       "      <td>126.028935</td>\n",
       "      <td>9.296941</td>\n",
       "      <td>71053.688126</td>\n",
       "      <td>0.030932</td>\n",
       "      <td>402.813548</td>\n",
       "      <td>-0.854332</td>\n",
       "      <td>-0.273900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>4</td>\n",
       "      <td>15.813673</td>\n",
       "      <td>380.628082</td>\n",
       "      <td>2.580501</td>\n",
       "      <td>1998.288</td>\n",
       "      <td>70.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>537</td>\n",
       "      <td>1998-04-01</td>\n",
       "      <td>69.179167</td>\n",
       "      <td>158.136730</td>\n",
       "      <td>8.991568</td>\n",
       "      <td>71262.155483</td>\n",
       "      <td>0.037028</td>\n",
       "      <td>379.456547</td>\n",
       "      <td>-1.017707</td>\n",
       "      <td>-0.005488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>5</td>\n",
       "      <td>12.578657</td>\n",
       "      <td>128.306992</td>\n",
       "      <td>2.108250</td>\n",
       "      <td>1998.371</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>620</td>\n",
       "      <td>1998-05-01</td>\n",
       "      <td>72.120833</td>\n",
       "      <td>125.786570</td>\n",
       "      <td>6.943908</td>\n",
       "      <td>100056.671947</td>\n",
       "      <td>0.031098</td>\n",
       "      <td>452.484785</td>\n",
       "      <td>-0.047913</td>\n",
       "      <td>-0.120904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>6</td>\n",
       "      <td>16.536440</td>\n",
       "      <td>138.153671</td>\n",
       "      <td>2.140362</td>\n",
       "      <td>1998.455</td>\n",
       "      <td>90.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>521</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>77.295833</td>\n",
       "      <td>165.364400</td>\n",
       "      <td>8.368127</td>\n",
       "      <td>69987.706731</td>\n",
       "      <td>0.024842</td>\n",
       "      <td>414.453910</td>\n",
       "      <td>-0.684110</td>\n",
       "      <td>-0.465511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month      SD_70       SL_70  SL_70_log10  fyear_CS  \\\n",
       "0  1998      2  12.301438   82.789337     1.917974  1998.123   \n",
       "1  1998      3  12.602894  159.079344     2.008504  1998.204   \n",
       "2  1998      4  15.813673  380.628082     2.580501  1998.288   \n",
       "3  1998      5  12.578657  128.306992     2.108250  1998.371   \n",
       "4  1998      6  16.536440  138.153671     2.140362  1998.455   \n",
       "\n",
       "   monthly_sunspots  std  observations       date  smoothed_sunspots  \\\n",
       "0              50.2  4.6           559 1998-02-01          61.745833   \n",
       "1              82.0  5.9           571 1998-03-01          65.370833   \n",
       "2              70.6  7.2           537 1998-04-01          69.179167   \n",
       "3              74.0  4.8           620 1998-05-01          72.120833   \n",
       "4              90.5  6.0           521 1998-06-01          77.295833   \n",
       "\n",
       "     SD_70*10  proton_density    proton_temp  He4toprotons  proton_speed  \\\n",
       "0  123.014380       10.668186   55818.621443      0.022320    377.004722   \n",
       "1  126.028935        9.296941   71053.688126      0.030932    402.813548   \n",
       "2  158.136730        8.991568   71262.155483      0.037028    379.456547   \n",
       "3  125.786570        6.943908  100056.671947      0.031098    452.484785   \n",
       "4  165.364400        8.368127   69987.706731      0.024842    414.453910   \n",
       "\n",
       "        PC1       PC2  \n",
       "0 -1.249865 -0.740865  \n",
       "1 -0.854332 -0.273900  \n",
       "2 -1.017707 -0.005488  \n",
       "3 -0.047913 -0.120904  \n",
       "4 -0.684110 -0.465511  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hcs_sun_ace.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting really bad results with this df. It's reduced partly because the ACE data only starts from 1998\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating copy of df and droping NAs\n",
    "hcs_sun_ace_model = hcs_sun_ace.copy().dropna()\n",
    "\n",
    "#Doing a sequential split\n",
    "split_point = int(len(hcs_sun_ace_model) * 0.8)  # 80% for training, 20% for testing\n",
    "\n",
    "#Selecting filters\n",
    "features = hcs_sun_ace_model[['monthly_sunspots','proton_density', 'proton_temp', 'He4toprotons','proton_speed','year','month', 'PC1','PC2']]\n",
    "features = hcs_sun_ace_model[['monthly_sunspots','year','month', 'PC1','PC2']]\n",
    "\n",
    "#Scaling features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to your features and transform them\n",
    "scaled = scaler.fit_transform(features)\n",
    "\n",
    "#Putting them in a df for the patition\n",
    "X = pd.DataFrame(scaled, columns=features.columns, index=features.index)\n",
    "\n",
    "#Outcome variables\n",
    "y_std = hcs_sun_ace_model['SD_70']\n",
    "y_slope = hcs_sun_ace_model['SL_70_log10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training and testing split for standard deviation prediction\n",
    "X_train_std = X.iloc[:split_point]\n",
    "X_test_std = X.iloc[split_point:]\n",
    "y_train_std = y_std.iloc[:split_point]\n",
    "y_test_std = y_std.iloc[split_point:]\n",
    "\n",
    "# # Training and testing split for slope prediction\n",
    "X_train_slope = X.iloc[:split_point]\n",
    "X_test_slope = X.iloc[split_point:]\n",
    "y_train_slope = y_slope.iloc[:split_point]\n",
    "y_test_slope = y_slope.iloc[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STD Model R^2 with ACE: -7.1497496274517545\n",
      "Slope Model R^2 with ACE: -8.776024666877731\n"
     ]
    }
   ],
   "source": [
    "# # Model for predicting standard deviation\n",
    "model_std = LinearRegression().fit(X_train_std, y_train_std)\n",
    "\n",
    "# # Model for predicting slope\n",
    "model_slope = LinearRegression().fit(X_train_slope, y_train_slope)\n",
    "\n",
    "# # Evaluating the models using R^2 score or other relevant metrics\n",
    "std_score = model_std.score(X_test_std, y_test_std)\n",
    "\n",
    "\n",
    "slope_score = model_slope.score(X_test_slope, y_test_slope)\n",
    "\n",
    "print(\"STD Model R^2 with ACE:\", std_score)\n",
    "print(\"Slope Model R^2 with ACE:\", slope_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying modeling without the ACE data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating copy of df and droping NAs\n",
    "hcs_sun_model = hcs_sun.copy().dropna()\n",
    "\n",
    "#Doing a sequential split\n",
    "split_point = int(len(hcs_sun_model) * 0.8)  # 80% for training, 20% for testing\n",
    "\n",
    "#Selecting filters\n",
    "features = hcs_sun_model[['monthly_sunspots','year','month']]\n",
    "\n",
    "#Scaling features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to your features and transform them\n",
    "scaled = scaler.fit_transform(features)\n",
    "\n",
    "#Putting them in a df for the patition\n",
    "X = pd.DataFrame(scaled, columns=features.columns, index=features.index)\n",
    "\n",
    "#Outcome variables\n",
    "y_std = hcs_sun_model['SD_70']\n",
    "y_slope = hcs_sun_model['SL_70_log10']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training and testing split for standard deviation prediction\n",
    "X_train_std = X.iloc[:split_point]\n",
    "X_test_std = X.iloc[split_point:]\n",
    "y_train_std = y_std.iloc[:split_point]\n",
    "y_test_std = y_std.iloc[split_point:]\n",
    "\n",
    "# # Training and testing split for slope prediction\n",
    "X_train_slope = X.iloc[:split_point]\n",
    "X_test_slope = X.iloc[split_point:]\n",
    "y_train_slope = y_slope.iloc[:split_point]\n",
    "y_test_slope = y_slope.iloc[split_point:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STD Model R^2: 0.5379844497275629\n",
      "Slope Model R^2: 0.5387953928646008\n"
     ]
    }
   ],
   "source": [
    "# # Model for predicting standard deviation\n",
    "model_std = LinearRegression().fit(X_train_std, y_train_std)\n",
    "\n",
    "# # Model for predicting slope\n",
    "model_slope = LinearRegression().fit(X_train_slope, y_train_slope)\n",
    "\n",
    "# # Evaluating the models using R^2 score or other relevant metrics\n",
    "std_score = model_std.score(X_test_std, y_test_std)\n",
    "\n",
    "\n",
    "slope_score = model_slope.score(X_test_slope, y_test_slope)\n",
    "\n",
    "print(\"STD Model R^2:\", std_score)\n",
    "print(\"Slope Model R^2:\", slope_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree STD Model R^2: 0.19492340514740136\n",
      "Decision Tree Slope Model R^2: 0.27049762451332604\n"
     ]
    }
   ],
   "source": [
    "# For standard deviation prediction\n",
    "dt_model_std = DecisionTreeRegressor().fit(X_train_std, y_train_std)\n",
    "dt_std_score = dt_model_std.score(X_test_std, y_test_std)\n",
    "\n",
    "# For slope prediction\n",
    "dt_model_slope = DecisionTreeRegressor().fit(X_train_slope, y_train_slope)\n",
    "dt_slope_score = dt_model_slope.score(X_test_slope, y_test_slope)\n",
    "\n",
    "print(\"Decision Tree STD Model R^2:\", dt_std_score)\n",
    "print(\"Decision Tree Slope Model R^2:\", dt_slope_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest STD Model R^2: 0.3556847054320107\n",
      "Random Forest Slope Model R^2: 0.237658245687545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# For standard deviation prediction\n",
    "rf_model_std = RandomForestRegressor().fit(X_train_std, y_train_std)\n",
    "rf_std_score = rf_model_std.score(X_test_std, y_test_std)\n",
    "\n",
    "# For slope prediction\n",
    "rf_model_slope = RandomForestRegressor().fit(X_train_slope, y_train_slope)\n",
    "rf_slope_score = rf_model_slope.score(X_test_slope, y_test_slope)\n",
    "\n",
    "print(\"Random Forest STD Model R^2:\", rf_std_score)\n",
    "print(\"Random Forest Slope Model R^2:\", rf_slope_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting STD Model R^2: 0.39568187586716197\n",
      "Gradient Boosting Slope Model R^2: 0.23049367430470613\n"
     ]
    }
   ],
   "source": [
    "# For standard deviation prediction\n",
    "gb_model_std = GradientBoostingRegressor().fit(X_train_std, y_train_std)\n",
    "gb_std_score = gb_model_std.score(X_test_std, y_test_std)\n",
    "\n",
    "# For slope prediction\n",
    "gb_model_slope = GradientBoostingRegressor().fit(X_train_slope, y_train_slope)\n",
    "gb_slope_score = gb_model_slope.score(X_test_slope, y_test_slope)\n",
    "\n",
    "print(\"Gradient Boosting STD Model R^2:\", gb_std_score)\n",
    "print(\"Gradient Boosting Slope Model R^2:\", gb_slope_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso STD R^2: 0.4919433925742881\n",
      "Lasso Slope R^2: 0.16709840060981218\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "lasso_std = Lasso(alpha=0.1).fit(X_train_std, y_train_std)\n",
    "lasso_slope = Lasso(alpha=0.1).fit(X_train_slope, y_train_slope)\n",
    "print(\"Lasso STD R^2:\", lasso_std.score(X_test_std, y_test_std))\n",
    "print(\"Lasso Slope R^2:\", lasso_slope.score(X_test_slope, y_test_slope))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge STD R^2: 0.5378143329290461\n",
      "Ridge Slope R^2: 0.5386447104507741\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "ridge_std = Ridge(alpha=0.1).fit(X_train_std, y_train_std)\n",
    "ridge_slope = Ridge(alpha=0.1).fit(X_train_slope, y_train_slope)\n",
    "print(\"Ridge STD R^2:\", ridge_std.score(X_test_std, y_test_std))\n",
    "print(\"Ridge Slope R^2:\", ridge_slope.score(X_test_slope, y_test_slope))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial STD R^2: 0.528332599789744\n",
      "Polynomial Slope R^2: 0.3903875124881989\n"
     ]
    }
   ],
   "source": [
    "# Polynomial Regression\n",
    "poly_std = make_pipeline(PolynomialFeatures(degree=2), LinearRegression()).fit(X_train_std, y_train_std)\n",
    "poly_slope = make_pipeline(PolynomialFeatures(degree=2), LinearRegression()).fit(X_train_slope, y_train_slope)\n",
    "print(\"Polynomial STD R^2:\", poly_std.score(X_test_std, y_test_std))\n",
    "print(\"Polynomial Slope R^2:\", poly_slope.score(X_test_slope, y_test_slope))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble STD Model R^2: 0.6748495264380412\n",
      "Ensemble Slope Model R^2: 0.5805798079902817\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Model (simple averaging for demonstration)\n",
    "predictions_lasso_std = lasso_std.predict(X_test_std)\n",
    "predictions_ridge_std = ridge_std.predict(X_test_std)\n",
    "predictions_poly_std = poly_std.predict(X_test_std)\n",
    "\n",
    "avg_predictions_std = (predictions_lasso_std + predictions_ridge_std + predictions_poly_std) / 3\n",
    "ensemble_std_score = r2_score(y_test_std, avg_predictions_std)\n",
    "print(\"Ensemble STD Model R^2:\", ensemble_std_score)\n",
    "\n",
    "# Repeat for slope, if desired\n",
    "predictions_lasso_slope = lasso_slope.predict(X_test_slope)\n",
    "predictions_ridge_slope = ridge_slope.predict(X_test_slope)\n",
    "predictions_poly_slope = poly_slope.predict(X_test_slope)\n",
    "\n",
    "avg_predictions_slope = (predictions_lasso_slope + predictions_ridge_slope + predictions_poly_slope) / 3\n",
    "ensemble_slope_score = r2_score(y_test_slope, avg_predictions_slope)\n",
    "print(\"Ensemble Slope Model R^2:\", ensemble_slope_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees STD Model R^2: 0.3689940332697761\n",
      "Extra Trees Slope Model R^2: 0.3074072503848383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# For the standard deviation prediction\n",
    "et_model_std = ExtraTreesRegressor(n_estimators=100, random_state=42).fit(X_train_std, y_train_std)\n",
    "et_std_score = et_model_std.score(X_test_std, y_test_std)\n",
    "print(\"Extra Trees STD Model R^2:\", et_std_score)\n",
    "\n",
    "# For the slope prediction\n",
    "et_model_slope = ExtraTreesRegressor(n_estimators=100, random_state=42).fit(X_train_slope, y_train_slope)\n",
    "et_slope_score = et_model_slope.score(X_test_slope, y_test_slope)\n",
    "print(\"Extra Trees Slope Model R^2:\", et_slope_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation using a Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 scores for STD across time splits: [ 0.18116071  0.70232017  0.62678013 -0.29133909  0.55595975]\n",
      "R^2 scores for Slope across time splits: [ 0.11237339  0.3223393   0.6285844  -0.66030711  0.46204864]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)  # Adjust the number of splits based on your dataset\n",
    "\n",
    "# Initialize your model - you can use the same model or different models for std and slope\n",
    "model_std = LinearRegression()\n",
    "model_slope = LinearRegression()\n",
    "\n",
    "# Evaluate the model for standard deviation\n",
    "scores_std = cross_val_score(model_std, X, y_std, cv=tscv, scoring='r2')\n",
    "print(\"R^2 scores for STD across time splits:\", scores_std)\n",
    "\n",
    "# Evaluate the model for slope\n",
    "scores_slope = cross_val_score(model_slope, X, y_slope, cv=tscv, scoring='r2')\n",
    "print(\"R^2 scores for Slope across time splits:\", scores_slope)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
